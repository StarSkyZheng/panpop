##################################################
# Structure variation calling using genome assambly and long reads
# Merge SVs from different tools using PanPop pipeline
# Author: Zeyu Zheng
# Time: 2023-2-8
# Email: asd63zhengzeyu@126.com
##################################################

import os
import pandas as pd
import shutil

configfile: "configs/software.yaml"
configfile: "configs/base.yaml"
configfile: "configs/config.pop3.yaml"

include: "subworkflows/util.py"

#conda: 'panpop'
conda: 'conda.panpop1.yaml'

SAMPLE_LIST = config['sample_reads_list_file']
INDEX_REF = config['ref']
MIN_SUPPORT_CALLER = config['MIN_SUPPORT_CALLER'] # Min support SV Caller count, Default 2

def exe_check_ret_abs_path(exe):
    if exe is None:
        raise Exception("Error!!! config error: {}".format(exe))
    if os.path.exists(exe) and os.path.isfile(exe) and os.access(exe, os.X_OK):
        abspath = os.path.abspath(exe)
        return abspath
    elif shutil.which(exe) is not None:
        abspath = shutil.which(exe)
        return abspath
    else:
        raise Exception("Can't find executable: {}".format(exe))


# paths
NGMLR = exe_check_ret_abs_path(config['ngmlr'])
SNIFFLES = exe_check_ret_abs_path(config['sniffles'])
CUTESV = exe_check_ret_abs_path(config['cutesv'])
SVIM = exe_check_ret_abs_path(config['svim'])
PICARD = exe_check_ret_abs_path(config['picard'])
#SURVIVOR = exe_check_ret_abs_path(config['survivor'])
PBSV = exe_check_ret_abs_path(config['pbsv'])
NUCMER = exe_check_ret_abs_path(config['nucmer'])
DELTAFILTER = exe_check_ret_abs_path(config['deltafilter'])
SHOWCOORDS = exe_check_ret_abs_path(config['showcoords'])
ASSEMBLYTICS = exe_check_ret_abs_path(config['assemblytics'])
BEDTOOLS = exe_check_ret_abs_path(config['bedtools'])
BCFTOOLS = exe_check_ret_abs_path(config['bcftools'])
TABIX = exe_check_ret_abs_path(config['tabix'])

ZWORKDIR = config['workdir']
workdir: ZWORKDIR



def read_input_sample_csv(file):
    df = pd.read_csv(file, sep='\t', index_col='sample')
    # must contain columns: sample, fq, AssmbFasta, platform
    if not set(['fq', 'AssmbFasta', 'platform']).issubset(df.columns):
        print(df.columns)
        raise Exception("Input file must contain columns: sample, fq, AssmbFasta, platform: {}".format(file))
    # set platform to lower case
    df['platform'] = df['platform'].str.lower()
    # platform must be one of: hifi, pacbio, ont (in lower case)
    if not set(['hifi', 'pb', 'ont']).issuperset(df['platform']):
        raise Exception("platform must be one of: hifi, pb, ont: {}".format(file))
    return df



#S2T = pd.read_csv(SAMPLE_LIST, sep='\t', index_col='sample')
S2T = read_input_sample_csv(SAMPLE_LIST)
SAMPLE_INDEX = S2T.index

include: "subworkflows/callSV3.py"
include: "subworkflows/mergeSV3.py"
include: "subworkflows/mergeSV3_pop.py"


rule all:
    input:
        expand("04_consensus_vcf/{sample}/10.concat_inv.split.sv.vcf.gz",sample=SAMPLE_INDEX),
        expand("04_consensus_vcf/{sample}/09.thin2.sort.vcf.gz", sample=SAMPLE_INDEX),
        expand("04_consensus_vcf/{sample}/00.inv.vcf.gz", sample=SAMPLE_INDEX),
        "05_merge_samples/08.realign0.sorted.vcf.gz",
        "05_merge_samples/15.thin2.sv.vcf.gz",
        "05_merge_samples/15.thin3.sv.vcf.gz",




