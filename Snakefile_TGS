##################################################
# Structure variation calling using genome assambly and long reads
# Merge SVs from different tools using PanPop pipeline
# Author: Zeyu Zheng
# Time: 2023-2-8
# Email: asd63zhengzeyu@126.com
##################################################

import os
import pandas as pd

configfile: "configs/software.yaml"
configfile: "configs/base.yaml"
configfile: "configs/config.TGS.yaml"

include: "subworkflows/util.py"

#conda: 'panpop'
#conda: 'conda.panpop1.yaml'

SAMPLE_LIST = config['sample_reads_list_file']
INDEX_REF = config['ref']
MIN_SUPPORT_CALLER_WITH_ASSB = config['MIN_SUPPORT_CALLER_WITH_ASSB'] # Min support SV Caller count, Default 2
MIN_SUPPORT_CALLER_WITHOUT_ASSB = config['MIN_SUPPORT_CALLER_WITHOUT_ASSB'] # Min support SV Caller count, Default 2
ZTMPDIR = 'tmp'
MAPPER=config['MAPPER']
MERGE_SV_POP = config['MERGE_SV_POP']

# paths
NGMLR = exe_check_ret_abs_path(config['ngmlr'])
SNIFFLES = exe_check_ret_abs_path(config['sniffles'])
CUTESV = exe_check_ret_abs_path(config['cutesv'])
SVIM = exe_check_ret_abs_path(config['svim'])
PICARD = exe_check_ret_abs_path(config['picard'])
#SURVIVOR = exe_check_ret_abs_path(config['survivor'])
PBSV = exe_check_ret_abs_path(config['pbsv'])
NUCMER = exe_check_ret_abs_path(config['nucmer'])
DELTAFILTER = exe_check_ret_abs_path(config['deltafilter'])
SHOWCOORDS = exe_check_ret_abs_path(config['showcoords'])
ASSEMBLYTICS = exe_check_ret_abs_path(config['assemblytics'])
BEDTOOLS = exe_check_ret_abs_path(config['bedtools'])
BCFTOOLS = exe_check_ret_abs_path(config['bcftools'])
TABIX = exe_check_ret_abs_path(config['tabix'])
MINIMAP2 = exe_check_ret_abs_path(config['minimap2'])
SAMTOOLS = exe_check_ret_abs_path(config['samtools'])
SVIM_ASM = exe_check_ret_abs_path(config['svim_asm'])

ZWORKDIR = config['workdir']
workdir: ZWORKDIR


for dir in [ZTMPDIR]:
    if not os.path.exists(dir):
        os.makedirs(dir)

def read_input_sample_csv(file):
    if not os.path.exists(file):
        raise Exception("Input file not exists: {}/{}".format(ZWORKDIR, file))
    df = pd.read_csv(file, sep='\t', index_col='sample')
    # must contain columns: sample, fq, AssmbFasta, platform
    if not set(['fq', 'AssmbFasta', 'platform']).issubset(df.columns):
        print(df.columns)
        raise Exception("Input file must contain columns: sample, fq, AssmbFasta, platform: {}".format(file))
    # set platform to lower case
    df['platform'] = df['platform'].str.lower()
    # platform must be one of: hifi, pacbio, ont (in lower case)
    if not set(['hifi', 'pb', 'ont']).issuperset(df['platform']):
        raise Exception("platform must be one of: hifi, pb, ont: {}".format(file))
    return df



#S2T = pd.read_csv(SAMPLE_LIST, sep='\t', index_col='sample')
S2T = read_input_sample_csv(SAMPLE_LIST)
SAMPLE_INDEX = S2T.index

include: "subworkflows/callSV3.py"
include: "subworkflows/mergeSV3.py"
include: "subworkflows/mergeSV3_pop.py"

if MERGE_SV_POP == True:
    rule all:
        input:
            expand("04_consensus_vcf/{sample}/01.merged.vcf.gz", sample=SAMPLE_INDEX),
            expand("04_consensus_vcf/{sample}/09.thin2.sorted.vcf.gz", sample=SAMPLE_INDEX),
            expand("04_consensus_vcf/{sample}/10.concat_inv.split.sv.vcf.gz",sample=SAMPLE_INDEX),
            expand("04_consensus_vcf/{sample}/00.inv.vcf.gz", sample=SAMPLE_INDEX),
            "05_merge_samples/08.realign0.sorted.vcf.gz",
            "05_merge_samples/15.thin2.sv.vcf.gz",
            "05_merge_samples/15.thin3.sv.vcf.gz",
else:
    rule all:
        input:
            expand("04_consensus_vcf/{sample}/01.merged.vcf.gz", sample=SAMPLE_INDEX),
            expand("04_consensus_vcf/{sample}/09.thin2.sorted.vcf.gz", sample=SAMPLE_INDEX),
            expand("04_consensus_vcf/{sample}/10.concat_inv.split.sv.vcf.gz",sample=SAMPLE_INDEX),
            expand("04_consensus_vcf/{sample}/00.inv.vcf.gz", sample=SAMPLE_INDEX),
